{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "author: Zeel B Patel\n",
    "badges: true\n",
    "categories:\n",
    "  - ML\n",
    "  - CV\n",
    "date: \"2025-02-10\"\n",
    "description: Compare your performance with a random baseline.\n",
    "title: Object Detection Random Baseline\n",
    "toc: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Random Baseline?\n",
    "Given a standard dataset with a fixed set of models, it is easier to compare the performance of different models. But what if we are working on a new model which has performance far from the best set of models but as a first step, we simply want to check if the model is learning anything at all. In such cases, it is useful to compare the performance of the model with a random baseline.\n",
    "\n",
    "# Proposed Idea\n",
    "\n",
    "* To formalize the problem, let's say for an arbitrary image, model predicts $k$ bounding boxes with sizes $(h_1, w_1), (h_2, w_2), \\ldots, (h_k, w_k)$.\n",
    "* A simple random baseline would be to generate $k$ random bounding boxes for that image with sizes $(h_1, w_1), (h_2, w_2), \\ldots, (h_k, w_k)$. In other words, we can simply move the predicted bounding boxes to random locations ensuring that the bounding boxes are within the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import supervision as sv\n",
    "from roboflow import Roboflow\n",
    "from dotenv import load_dotenv\n",
    "from ultralytics import YOLO\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "data_location = \"/tmp/poker-cards-fmjio\"\n",
    "\n",
    "rf = Roboflow(api_key=os.getenv(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(\"roboflow-jvuqo\").project(\"poker-cards-fmjio\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov8\", location=data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11m\")\n",
    "\n",
    "model.train(data=f\"{data_location}/data.yaml\", epochs=1, project=\"/tmp/poker-cards-fmjio\", exist_ok=True)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = sv.DetectionDataset.from_yolo(f\"{data_location}/test/images\", f\"{data_location}/test/labels\", f\"{data_location}/data.yaml\")\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8973664711cf4331835986ac2c90eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_list = []\n",
    "detections_list = []\n",
    "for _, img, annotations in tqdm(test_dataset):\n",
    "    results = model.predict(img, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    annotations_list.append(annotations)\n",
    "    detections_list.append(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1417744455736285"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP = sv.metrics.MeanAveragePrecision().update(detections_list, annotations_list).compute()\n",
    "mAP.map50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per our assumption, we would simply need to randomly move the existing bounding boxes keeping their sizes constant with the following constraints:\n",
    "\n",
    "* The bounding box should be within the image boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd580f70063b474d95e028a8950e089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50: 0.04 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "min_size = 0\n",
    "max_size = model.args['imgsz']\n",
    "\n",
    "mAPs = []\n",
    "for random_seed in tqdm(range(100)):\n",
    "    np.random.seed(random_seed)\n",
    "    random_detections_list = []\n",
    "    for detections in detections_list:\n",
    "        random_detections = deepcopy(detections)\n",
    "        shift = np.random.rand(len(detections))\n",
    "        lower_limit = - detections.xyxy.min(axis=1) + 1e-6\n",
    "        upper_limit = max_size - detections.xyxy.max(axis=1) - 1e-6\n",
    "        transformed_shift = lower_limit + shift * (upper_limit - lower_limit)\n",
    "        random_detections.xyxy = random_detections.xyxy + transformed_shift.reshape(-1, 1)\n",
    "        random_detections_list.append(random_detections)\n",
    "        \n",
    "    mAP = sv.metrics.MeanAveragePrecision().update(random_detections_list, annotations_list).compute()\n",
    "    mAPs.append(mAP.map50)\n",
    "    \n",
    "print(f\"mAP50: {mAP.map50:.2f} +/- {np.std(mAPs):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also modify the confidence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ab8c90b98d439b9bbacefc9083d08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP50: 0.03 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "min_size = 0\n",
    "max_size = model.args['imgsz']\n",
    "\n",
    "mAPs = []\n",
    "for random_seed in tqdm(range(100)):\n",
    "    np.random.seed(random_seed)\n",
    "    random_detections_list = []\n",
    "    for detections in detections_list:\n",
    "        random_detections = deepcopy(detections)\n",
    "        shift = np.random.rand(len(detections))\n",
    "        lower_limit = - detections.xyxy.min(axis=1) + 1e-6\n",
    "        upper_limit = max_size - detections.xyxy.max(axis=1) - 1e-6\n",
    "        transformed_shift = lower_limit + shift * (upper_limit - lower_limit)\n",
    "        random_detections.xyxy = random_detections.xyxy + transformed_shift.reshape(-1, 1)\n",
    "        random_detections.confidence = np.random.rand(len(detections))\n",
    "        random_detections_list.append(random_detections)\n",
    "        \n",
    "    mAP = sv.metrics.MeanAveragePrecision().update(random_detections_list, annotations_list).compute()\n",
    "    mAPs.append(mAP.map50)\n",
    "    \n",
    "print(f\"mAP50: {mAP.map50:.2f} +/- {np.std(mAPs):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in this case, our model got better than the random baseline with a single epoch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeel_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
