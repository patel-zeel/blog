{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd9905c6",
   "metadata": {},
   "source": [
    "---\n",
    "author: Zeel B Patel\n",
    "badges: true\n",
    "categories:\n",
    "  - PyTorch\n",
    "date: \"2025-11-20\"\n",
    "description: Testing comprehensive memory usage in PyTorch models\n",
    "title: Comprehensive GPU Memory Tests in PyTorch\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a399858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Testing on: Tesla V100-SXM3-32GB\n",
      "üìä Total GPU Memory: 31.73 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Verify CUDA availability\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. This notebook requires a GPU.\")\n",
    "\n",
    "device = 0\n",
    "print(f\"üéØ Testing on: {torch.cuda.get_device_name(device)}\")\n",
    "print(f\"üìä Total GPU Memory: {torch.cuda.get_device_properties(device).total_memory / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4238a8",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94323203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "def get_memory_stats(device=0):\n",
    "    \"\"\"Get current GPU memory statistics in GB\"\"\"\n",
    "    allocated = torch.cuda.memory_allocated(device) / (1024**3)\n",
    "    reserved = torch.cuda.memory_reserved(device) / (1024**3)\n",
    "    return allocated, reserved\n",
    "\n",
    "def reset_memory():\n",
    "    \"\"\"Clean slate for each experiment\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "\n",
    "def create_tensors_no_return(device=0, size_gb=2.0):\n",
    "    \"\"\"Create tensors but don't return them\"\"\"\n",
    "    elements = int(size_gb * 1024**3 / 4)\n",
    "    tensor = torch.randn(elements, dtype=torch.float32, device=f'cuda:{device}')\n",
    "    result = torch.sum(tensor)\n",
    "    return None  # Explicit no return\n",
    "\n",
    "def create_tensors_with_return(device=0, size_gb=2.0):\n",
    "    \"\"\"Create tensors and return them\"\"\"\n",
    "    elements = int(size_gb * 1024**3 / 4)\n",
    "    tensor = torch.randn(elements, dtype=torch.float32, device=f'cuda:{device}')\n",
    "    result = torch.sum(tensor)\n",
    "    return tensor, result\n",
    "\n",
    "def create_tensor_list(device=0, num_tensors=5, size_gb_each=0.4):\n",
    "    \"\"\"Create a list of tensors\"\"\"\n",
    "    elements_per_tensor = int(size_gb_each * 1024**3 / 4)\n",
    "    tensor_list = []\n",
    "    for i in range(num_tensors):\n",
    "        tensor = torch.randn(elements_per_tensor, dtype=torch.float32, device=f'cuda:{device}')\n",
    "        tensor_list.append(tensor)\n",
    "    return tensor_list\n",
    "\n",
    "def create_nested_structure(device=0):\n",
    "    \"\"\"Create nested dict/list structure with tensors\"\"\"\n",
    "    elements = int(0.3 * 1024**3 / 4)\n",
    "    structure = {\n",
    "        'tensors': [\n",
    "            torch.randn(elements, device=f'cuda:{device}'),\n",
    "            torch.randn(elements, device=f'cuda:{device}')\n",
    "        ],\n",
    "        'nested': {\n",
    "            'more_tensors': [\n",
    "                torch.randn(elements, device=f'cuda:{device}'),\n",
    "                torch.randn(elements, device=f'cuda:{device}')\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    return structure\n",
    "\n",
    "# Storage for all results\n",
    "results = []\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f469a9",
   "metadata": {},
   "source": [
    "## Experiment Group 1: Function Return Behavior\n",
    "Testing how returning vs not returning tensors affects memory lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444eead4",
   "metadata": {},
   "source": [
    "### Exp 1.1: No Return, No Cache Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd217814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:  Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:   Alloc=0.000GB, Res=2.002GB\n",
      "\n",
      "üí° Tensors freed (allocated‚Üí0), but memory stays cached (reserved high)\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "create_tensors_no_return(device, size_gb=2.0)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Function Return',\n",
    "    'Experiment': 'No return, No cache clear',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_after,\n",
    "    'Res Clear': res_after\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:  Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:   Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"\\nüí° Tensors freed (allocated‚Üí0), but memory stays cached (reserved high)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f8a86",
   "metadata": {},
   "source": [
    "### Exp 1.2: No Return, WITH Cache Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58e5601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=0.000GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° Complete cleanup: Both allocated and reserved drop to 0\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "create_tensors_no_return(device, size_gb=2.0)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Function Return',\n",
    "    'Experiment': 'No return, WITH cache clear',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° Complete cleanup: Both allocated and reserved drop to 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93532a2",
   "metadata": {},
   "source": [
    "### Exp 1.3: WITH Return, Holding Reference, No Cache Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b194760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:  Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:   Alloc=2.000GB, Res=2.002GB\n",
      "\n",
      "üí° Both stay high: Active references keep memory allocated\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensors = create_tensors_with_return(device, size_gb=2.0)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Function Return',\n",
    "    'Experiment': 'WITH return, holding ref',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_after,\n",
    "    'Res Clear': res_after\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:  Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:   Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"\\nüí° Both stay high: Active references keep memory allocated\")\n",
    "\n",
    "del tensors  # Clean up for next experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecff2e",
   "metadata": {},
   "source": [
    "### Exp 1.4: WITH Return, Delete Reference, WITH Cache Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "402e3a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.000GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° Proper cleanup: del + empty_cache() fully releases memory\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensors = create_tensors_with_return(device, size_gb=2.0)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "del tensors\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Function Return',\n",
    "    'Experiment': 'WITH return, del ref + cache clear',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° Proper cleanup: del + empty_cache() fully releases memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a1527",
   "metadata": {},
   "source": [
    "## Experiment Group 2: List Reference Management\n",
    "Testing different ways to delete lists containing tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecc1b57",
   "metadata": {},
   "source": [
    "### Exp 2.1: Delete List Directly with `del`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee71f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.002GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° 'del list' instantly frees all tensors in the list\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "del tensor_list\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'List Management',\n",
    "    'Experiment': 'del list',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° 'del list' instantly frees all tensors in the list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e8f30",
   "metadata": {},
   "source": [
    "### Exp 2.2: Clear List with `.clear()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1666a31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.002GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° 'list.clear()' works identically to 'del list'\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "tensor_list.clear()\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'List Management',\n",
    "    'Experiment': 'list.clear()',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° 'list.clear()' works identically to 'del list'\")\n",
    "\n",
    "del tensor_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23081a4",
   "metadata": {},
   "source": [
    "### Exp 2.3: Reassign to Empty List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5284d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.002GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° 'list = []' also frees old list contents via garbage collection\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "tensor_list = []  # Reassign\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'List Management',\n",
    "    'Experiment': 'reassign to []',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° 'list = []' also frees old list contents via garbage collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f72027",
   "metadata": {},
   "source": [
    "### Exp 2.4: Delete Elements in Loop (Backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864de988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.002GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° Loop deletion works but is unnecessarily complex - just use 'del list'\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "# Delete backward to avoid index shifting\n",
    "for i in range(len(tensor_list) - 1, -1, -1):\n",
    "    del tensor_list[i]\n",
    "del tensor_list\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'List Management',\n",
    "    'Experiment': 'loop deletion (backward)',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° Loop deletion works but is unnecessarily complex - just use 'del list'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440cc4f",
   "metadata": {},
   "source": [
    "## Experiment Group 3: Multiple References & Complex Scenarios\n",
    "Testing edge cases with shared references and nested structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bf4039",
   "metadata": {},
   "source": [
    "### Exp 3.1: List Element Assigned to Another Variable (`out`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e75c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:                Alloc=0.000GB, Res=0.000GB\n",
      "üìç After (5 tensors):     Alloc=2.002GB, Res=2.002GB\n",
      "üìç After del list:        Alloc=0.400GB, Res=2.002GB\n",
      "üìç After del out + clear: Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° CRITICAL: 'out' kept 1 tensor alive (~0.4GB) after list deletion\n",
      "   Only after 'del out' did all memory get freed!\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "# Save reference to one element\n",
    "out = tensor_list[2]  # Keep reference to middle element\n",
    "del tensor_list  # Delete the list\n",
    "\n",
    "alloc_after_del_list, res_after_del_list = get_memory_stats(device)\n",
    "\n",
    "# Now delete the 'out' reference\n",
    "del out\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Multiple References',\n",
    "    'Experiment': 'List elem ‚Üí out var, del list',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after_del_list,  # After del list (out still alive)\n",
    "    'Res After': res_after_del_list,\n",
    "    'Alloc Clear': alloc_clear,  # After del out + cache clear\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:                Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After (5 tensors):     Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç After del list:        Alloc={alloc_after_del_list:.3f}GB, Res={res_after_del_list:.3f}GB\")\n",
    "print(f\"üìç After del out + clear: Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° CRITICAL: 'out' kept 1 tensor alive (~0.4GB) after list deletion\")\n",
    "print(f\"   Only after 'del out' did all memory get freed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9284487",
   "metadata": {},
   "source": [
    "### Exp 3.2: Tensor Referenced by List AND Separate Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "087d0d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:            Alloc=0.000GB, Res=0.000GB\n",
      "üìç After creation:    Alloc=1.000GB, Res=1.000GB\n",
      "üìç After del list:    Alloc=1.000GB, Res=1.000GB\n",
      "üìç After del tensor:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° Same tensor referenced twice: Survives until ALL references deleted\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor = torch.randn(int(1.0 * 1024**3 / 4), device=f'cuda:{device}')\n",
    "tensor_list = [tensor]  # List references the same tensor\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "del tensor_list  # Delete list\n",
    "alloc_after_del_list, res_after_del_list = get_memory_stats(device)\n",
    "\n",
    "del tensor  # Delete variable\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Multiple References',\n",
    "    'Experiment': 'Same tensor in list + var',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after_del_list,  # After del list only\n",
    "    'Res After': res_after_del_list,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:            Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After creation:    Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç After del list:    Alloc={alloc_after_del_list:.3f}GB, Res={res_after_del_list:.3f}GB\")\n",
    "print(f\"üìç After del tensor:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° Same tensor referenced twice: Survives until ALL references deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840032d",
   "metadata": {},
   "source": [
    "### Exp 3.3: Nested Dictionary/List Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700fa662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=1.203GB, Res=1.203GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° Python's GC recursively frees nested structures - no manual traversal needed\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "nested = create_nested_structure(device)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "del nested  # Single del handles entire nested structure\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Multiple References',\n",
    "    'Experiment': 'Nested dict/list structure',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after,\n",
    "    'Res After': res_after,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° Python's GC recursively frees nested structures - no manual traversal needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021adc7",
   "metadata": {},
   "source": [
    "### Exp 3.4: Explicit Garbage Collection (`gc.collect()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18ba736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Before:       Alloc=0.000GB, Res=0.000GB\n",
      "üìç After:        Alloc=2.002GB, Res=2.002GB\n",
      "üìç After del:    Alloc=0.000GB, Res=2.002GB\n",
      "üìç After gc:     Alloc=0.000GB, Res=2.002GB\n",
      "üìç Cache Clear:  Alloc=0.000GB, Res=0.000GB\n",
      "\n",
      "üí° gc.collect() makes NO difference - Python's refcounting handles it instantly\n"
     ]
    }
   ],
   "source": [
    "reset_memory()\n",
    "\n",
    "alloc_before, res_before = get_memory_stats(device)\n",
    "tensor_list = create_tensor_list(device, num_tensors=5, size_gb_each=0.4)\n",
    "alloc_after, res_after = get_memory_stats(device)\n",
    "\n",
    "del tensor_list\n",
    "alloc_after_del, res_after_del = get_memory_stats(device)\n",
    "\n",
    "gc.collect()  # Force garbage collection\n",
    "alloc_after_gc, res_after_gc = get_memory_stats(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "alloc_clear, res_clear = get_memory_stats(device)\n",
    "\n",
    "results.append({\n",
    "    'Group': 'Multiple References',\n",
    "    'Experiment': 'with gc.collect()',\n",
    "    'Alloc Before': alloc_before,\n",
    "    'Res Before': res_before,\n",
    "    'Alloc After': alloc_after_gc,  # After gc.collect()\n",
    "    'Res After': res_after_gc,\n",
    "    'Alloc Clear': alloc_clear,\n",
    "    'Res Clear': res_clear\n",
    "})\n",
    "\n",
    "print(f\"üìç Before:       Alloc={alloc_before:.3f}GB, Res={res_before:.3f}GB\")\n",
    "print(f\"üìç After:        Alloc={alloc_after:.3f}GB, Res={res_after:.3f}GB\")\n",
    "print(f\"üìç After del:    Alloc={alloc_after_del:.3f}GB, Res={res_after_del:.3f}GB\")\n",
    "print(f\"üìç After gc:     Alloc={alloc_after_gc:.3f}GB, Res={res_after_gc:.3f}GB\")\n",
    "print(f\"üìç Cache Clear:  Alloc={alloc_clear:.3f}GB, Res={res_clear:.3f}GB\")\n",
    "print(f\"\\nüí° gc.collect() makes NO difference - Python's refcounting handles it instantly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ae752",
   "metadata": {},
   "source": [
    "## üìä Comprehensive Results Table\n",
    "\n",
    "Summary of all experiments showing memory behavior across different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089271dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_406856/598390223.py:18: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_df = df.style.applymap(color_memory, subset=numeric_cols) \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ce05f th {\n",
       "  background-color: #2c3e50;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "  padding: 10px;\n",
       "  font-size: 12px;\n",
       "}\n",
       "#T_ce05f td {\n",
       "  padding: 8px;\n",
       "}\n",
       "#T_ce05f tr:hover {\n",
       "  background-color: #f5f5f5;\n",
       "}\n",
       "#T_ce05f_row0_col0, #T_ce05f_row0_col1, #T_ce05f_row1_col0, #T_ce05f_row1_col1, #T_ce05f_row2_col0, #T_ce05f_row2_col1, #T_ce05f_row3_col0, #T_ce05f_row3_col1, #T_ce05f_row4_col0, #T_ce05f_row4_col1, #T_ce05f_row5_col0, #T_ce05f_row5_col1, #T_ce05f_row6_col0, #T_ce05f_row6_col1, #T_ce05f_row7_col0, #T_ce05f_row7_col1, #T_ce05f_row8_col0, #T_ce05f_row8_col1, #T_ce05f_row9_col0, #T_ce05f_row9_col1, #T_ce05f_row10_col0, #T_ce05f_row10_col1, #T_ce05f_row11_col0, #T_ce05f_row11_col1 {\n",
       "  text-align: left;\n",
       "  font-size: 11px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_ce05f_row0_col2, #T_ce05f_row0_col3, #T_ce05f_row0_col4, #T_ce05f_row0_col6, #T_ce05f_row1_col2, #T_ce05f_row1_col3, #T_ce05f_row1_col4, #T_ce05f_row1_col6, #T_ce05f_row1_col7, #T_ce05f_row2_col2, #T_ce05f_row2_col3, #T_ce05f_row3_col2, #T_ce05f_row3_col3, #T_ce05f_row3_col6, #T_ce05f_row3_col7, #T_ce05f_row4_col2, #T_ce05f_row4_col3, #T_ce05f_row4_col6, #T_ce05f_row4_col7, #T_ce05f_row5_col2, #T_ce05f_row5_col3, #T_ce05f_row5_col6, #T_ce05f_row5_col7, #T_ce05f_row6_col2, #T_ce05f_row6_col3, #T_ce05f_row6_col6, #T_ce05f_row6_col7, #T_ce05f_row7_col2, #T_ce05f_row7_col3, #T_ce05f_row7_col6, #T_ce05f_row7_col7, #T_ce05f_row8_col2, #T_ce05f_row8_col3, #T_ce05f_row8_col6, #T_ce05f_row8_col7, #T_ce05f_row9_col2, #T_ce05f_row9_col3, #T_ce05f_row9_col6, #T_ce05f_row9_col7, #T_ce05f_row10_col2, #T_ce05f_row10_col3, #T_ce05f_row10_col6, #T_ce05f_row10_col7, #T_ce05f_row11_col2, #T_ce05f_row11_col3, #T_ce05f_row11_col4, #T_ce05f_row11_col6, #T_ce05f_row11_col7 {\n",
       "  background-color: #d4edda;\n",
       "  color: #155724;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  font-size: 11px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_ce05f_row0_col5, #T_ce05f_row0_col7, #T_ce05f_row1_col5, #T_ce05f_row2_col4, #T_ce05f_row2_col5, #T_ce05f_row2_col6, #T_ce05f_row2_col7, #T_ce05f_row3_col4, #T_ce05f_row3_col5, #T_ce05f_row4_col4, #T_ce05f_row4_col5, #T_ce05f_row5_col4, #T_ce05f_row5_col5, #T_ce05f_row6_col4, #T_ce05f_row6_col5, #T_ce05f_row7_col4, #T_ce05f_row7_col5, #T_ce05f_row8_col5, #T_ce05f_row9_col4, #T_ce05f_row9_col5, #T_ce05f_row10_col4, #T_ce05f_row10_col5, #T_ce05f_row11_col5 {\n",
       "  background-color: #f8d7da;\n",
       "  color: #721c24;\n",
       "  text-align: left;\n",
       "  font-size: 11px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_ce05f_row8_col4 {\n",
       "  background-color: #fff3cd;\n",
       "  color: #856404;\n",
       "  text-align: left;\n",
       "  font-size: 11px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ce05f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce05f_level0_col0\" class=\"col_heading level0 col0\" >Group</th>\n",
       "      <th id=\"T_ce05f_level0_col1\" class=\"col_heading level0 col1\" >Experiment</th>\n",
       "      <th id=\"T_ce05f_level0_col2\" class=\"col_heading level0 col2\" >Alloc Before</th>\n",
       "      <th id=\"T_ce05f_level0_col3\" class=\"col_heading level0 col3\" >Res Before</th>\n",
       "      <th id=\"T_ce05f_level0_col4\" class=\"col_heading level0 col4\" >Alloc After</th>\n",
       "      <th id=\"T_ce05f_level0_col5\" class=\"col_heading level0 col5\" >Res After</th>\n",
       "      <th id=\"T_ce05f_level0_col6\" class=\"col_heading level0 col6\" >Alloc Clear</th>\n",
       "      <th id=\"T_ce05f_level0_col7\" class=\"col_heading level0 col7\" >Res Clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ce05f_row0_col0\" class=\"data row0 col0\" >Function Return</td>\n",
       "      <td id=\"T_ce05f_row0_col1\" class=\"data row0 col1\" >No return, No cache clear</td>\n",
       "      <td id=\"T_ce05f_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row0_col5\" class=\"data row0 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row0_col6\" class=\"data row0 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row0_col7\" class=\"data row0 col7\" >2.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ce05f_row1_col0\" class=\"data row1 col0\" >Function Return</td>\n",
       "      <td id=\"T_ce05f_row1_col1\" class=\"data row1 col1\" >No return, WITH cache clear</td>\n",
       "      <td id=\"T_ce05f_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row1_col5\" class=\"data row1 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ce05f_row2_col0\" class=\"data row2 col0\" >Function Return</td>\n",
       "      <td id=\"T_ce05f_row2_col1\" class=\"data row2 col1\" >WITH return, holding ref</td>\n",
       "      <td id=\"T_ce05f_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row2_col4\" class=\"data row2 col4\" >2.000000</td>\n",
       "      <td id=\"T_ce05f_row2_col5\" class=\"data row2 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row2_col6\" class=\"data row2 col6\" >2.000000</td>\n",
       "      <td id=\"T_ce05f_row2_col7\" class=\"data row2 col7\" >2.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ce05f_row3_col0\" class=\"data row3 col0\" >Function Return</td>\n",
       "      <td id=\"T_ce05f_row3_col1\" class=\"data row3 col1\" >WITH return, del ref + cache clear</td>\n",
       "      <td id=\"T_ce05f_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row3_col4\" class=\"data row3 col4\" >2.000000</td>\n",
       "      <td id=\"T_ce05f_row3_col5\" class=\"data row3 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row3_col6\" class=\"data row3 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row3_col7\" class=\"data row3 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ce05f_row4_col0\" class=\"data row4 col0\" >List Management</td>\n",
       "      <td id=\"T_ce05f_row4_col1\" class=\"data row4 col1\" >del list</td>\n",
       "      <td id=\"T_ce05f_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row4_col4\" class=\"data row4 col4\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row4_col5\" class=\"data row4 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row4_col6\" class=\"data row4 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row4_col7\" class=\"data row4 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ce05f_row5_col0\" class=\"data row5 col0\" >List Management</td>\n",
       "      <td id=\"T_ce05f_row5_col1\" class=\"data row5 col1\" >list.clear()</td>\n",
       "      <td id=\"T_ce05f_row5_col2\" class=\"data row5 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row5_col4\" class=\"data row5 col4\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row5_col5\" class=\"data row5 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row5_col6\" class=\"data row5 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row5_col7\" class=\"data row5 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ce05f_row6_col0\" class=\"data row6 col0\" >List Management</td>\n",
       "      <td id=\"T_ce05f_row6_col1\" class=\"data row6 col1\" >reassign to []</td>\n",
       "      <td id=\"T_ce05f_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row6_col4\" class=\"data row6 col4\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row6_col5\" class=\"data row6 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row6_col7\" class=\"data row6 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ce05f_row7_col0\" class=\"data row7 col0\" >List Management</td>\n",
       "      <td id=\"T_ce05f_row7_col1\" class=\"data row7 col1\" >loop deletion (backward)</td>\n",
       "      <td id=\"T_ce05f_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row7_col4\" class=\"data row7 col4\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row7_col5\" class=\"data row7 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row7_col6\" class=\"data row7 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row7_col7\" class=\"data row7 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ce05f_row8_col0\" class=\"data row8 col0\" >Multiple References</td>\n",
       "      <td id=\"T_ce05f_row8_col1\" class=\"data row8 col1\" >List elem ‚Üí out var, del list</td>\n",
       "      <td id=\"T_ce05f_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row8_col4\" class=\"data row8 col4\" >0.400000</td>\n",
       "      <td id=\"T_ce05f_row8_col5\" class=\"data row8 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row8_col6\" class=\"data row8 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row8_col7\" class=\"data row8 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ce05f_row9_col0\" class=\"data row9 col0\" >Multiple References</td>\n",
       "      <td id=\"T_ce05f_row9_col1\" class=\"data row9 col1\" >Same tensor in list + var</td>\n",
       "      <td id=\"T_ce05f_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row9_col4\" class=\"data row9 col4\" >1.000000</td>\n",
       "      <td id=\"T_ce05f_row9_col5\" class=\"data row9 col5\" >1.000000</td>\n",
       "      <td id=\"T_ce05f_row9_col6\" class=\"data row9 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row9_col7\" class=\"data row9 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ce05f_row10_col0\" class=\"data row10 col0\" >Multiple References</td>\n",
       "      <td id=\"T_ce05f_row10_col1\" class=\"data row10 col1\" >Nested dict/list structure</td>\n",
       "      <td id=\"T_ce05f_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row10_col4\" class=\"data row10 col4\" >1.203000</td>\n",
       "      <td id=\"T_ce05f_row10_col5\" class=\"data row10 col5\" >1.203000</td>\n",
       "      <td id=\"T_ce05f_row10_col6\" class=\"data row10 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row10_col7\" class=\"data row10 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce05f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ce05f_row11_col0\" class=\"data row11 col0\" >Multiple References</td>\n",
       "      <td id=\"T_ce05f_row11_col1\" class=\"data row11 col1\" >with gc.collect()</td>\n",
       "      <td id=\"T_ce05f_row11_col2\" class=\"data row11 col2\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row11_col4\" class=\"data row11 col4\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row11_col5\" class=\"data row11 col5\" >2.002000</td>\n",
       "      <td id=\"T_ce05f_row11_col6\" class=\"data row11 col6\" >0.000000</td>\n",
       "      <td id=\"T_ce05f_row11_col7\" class=\"data row11 col7\" >0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa4622718d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "LEGEND\n",
      "====================================================================================================\n",
      "üü¢ Green (0.000 GB):  Memory fully released\n",
      "üü° Yellow (<0.5 GB):  Partial memory usage\n",
      "üî¥ Red (‚â•0.5 GB):     Significant memory usage\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Round to 3 decimals for readability\n",
    "numeric_cols = ['Alloc Before', 'Res Before', 'Alloc After', 'Res After', 'Alloc Clear', 'Res Clear']\n",
    "df[numeric_cols] = df[numeric_cols].round(3)\n",
    "\n",
    "# Create styled HTML table\n",
    "def color_memory(val):\n",
    "    \"\"\"Color code memory values\"\"\"\n",
    "    if val == 0.000:\n",
    "        return 'background-color: #d4edda; color: #155724; font-weight: bold'  # Green\n",
    "    elif val < 0.5:\n",
    "        return 'background-color: #fff3cd; color: #856404'  # Yellow\n",
    "    else:\n",
    "        return 'background-color: #f8d7da; color: #721c24'  # Red\n",
    "\n",
    "styled_df = df.style.applymap(color_memory, subset=numeric_cols) \\\n",
    "    .set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'font-size': '11px',\n",
    "        'border': '1px solid #ddd'\n",
    "    }) \\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#2c3e50'), ('color', 'white'), \n",
    "                                      ('font-weight', 'bold'), ('text-align', 'center'),\n",
    "                                      ('padding', '10px'), ('font-size', '12px')]},\n",
    "        {'selector': 'td', 'props': [('padding', '8px')]},\n",
    "        {'selector': 'tr:hover', 'props': [('background-color', '#f5f5f5')]}\n",
    "    ])\n",
    "\n",
    "display(styled_df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"LEGEND\")\n",
    "print(\"=\"*100)\n",
    "print(\"üü¢ Green (0.000 GB):  Memory fully released\")\n",
    "print(\"üü° Yellow (<0.5 GB):  Partial memory usage\")\n",
    "print(\"üî¥ Red (‚â•0.5 GB):     Significant memory usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad44728",
   "metadata": {},
   "source": [
    "## üéØ Key Insights & Best Practices\n",
    "\n",
    "### Memory Behavior Summary\n",
    "\n",
    "1. **`memory_allocated()` vs `memory_reserved()`**\n",
    "   - **Allocated**: Live tensor memory (active Python references)\n",
    "   - **Reserved**: Total cached memory (allocated + free cache blocks)\n",
    "   - Reserved stays high even after tensors are freed (caching optimization)\n",
    "\n",
    "2. **Function Return Behavior**\n",
    "   - ‚úÖ **No return**: Tensors freed immediately after function exits\n",
    "   - ‚ö†Ô∏è **With return**: Tensors stay alive as long as references exist\n",
    "   - üîë **Key**: Reference lifetime determines memory lifetime\n",
    "\n",
    "3. **List Deletion Methods (All Equivalent)**\n",
    "   - `del list` ‚úì\n",
    "   - `list.clear()` ‚úì\n",
    "   - `list = []` ‚úì\n",
    "   - Loop deletion ‚úì (but unnecessarily complex)\n",
    "\n",
    "4. **Multiple References = Extended Lifetime**\n",
    "   - If `out = tensor_list[i]` exists, that tensor survives list deletion\n",
    "   - Memory freed only when **ALL** references are deleted\n",
    "   - Python's reference counting handles this automatically\n",
    "\n",
    "5. **Nested Structures**\n",
    "   - Single `del` on top-level structure recursively frees everything\n",
    "   - No manual traversal needed - Python's GC handles it\n",
    "\n",
    "6. **Cache Management**\n",
    "   - `torch.cuda.empty_cache()` only releases **unused** cached memory\n",
    "   - Cannot release memory for live tensors (active references)\n",
    "   - Must delete references first, then call `empty_cache()`\n",
    "\n",
    "7. **Garbage Collection**\n",
    "   - `gc.collect()` usually **NOT needed** for PyTorch tensors\n",
    "   - Python's reference counting frees memory immediately\n",
    "   - Only helpful for circular reference cycles (rare with tensors)\n",
    "\n",
    "### ‚ö†Ô∏è Common Pitfalls\n",
    "\n",
    "1. **Hidden references** in global scope, class attributes, or closures\n",
    "2. **Calling `empty_cache()` while holding references** (does nothing)\n",
    "3. **Assuming `memory_reserved()` indicates active usage** (it's cache!)\n",
    "4. **Manual loop deletion instead of `del list`** (error-prone)\n",
    "\n",
    "### ‚úÖ Best Practice Checklist\n",
    "\n",
    "- [ ] Delete references when done: `del tensors`\n",
    "- [ ] Clear cache after deletion: `torch.cuda.empty_cache()`\n",
    "- [ ] Check for hidden references (list elements, class attrs, etc.)\n",
    "- [ ] Monitor both `memory_allocated()` and `memory_reserved()`\n",
    "- [ ] Use simple deletion (`del`, `.clear()`) over manual loops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
